{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import tensor.tensor_product_wrapper as tp\n",
    "from utils.plotting_utils import montage_array, slice_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import similarity_metrics as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io\n",
    "import utils.starplus_utils as starp\n",
    "from numpy.linalg import norm\n",
    "from tensor.utils import assert_compatile_sizes_modek, reshape, make_axis_iterable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from numpy.linalg import svd\n",
    "from tensor.mode_k import modek_unfold\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from scipy.stats import ortho_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# choose product type {'f', 't', 'c'ï¼Œ'm'}\n",
    "# m-product using haarMatrix\n",
    "prod_type = 'm'\n",
    "\n",
    "\n",
    "#choose M {'band','haar','data dependent','random orthogonal'}\n",
    "#ONLY USING M-PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# define projection\n",
    "def projection_m_prod_type(A, U, M):\n",
    "    if M == 'band':\n",
    "        # Banded Matrix\n",
    "        training_coeff = tp.ten_prod(tp.ten_tran(U, prod_type=prod_type), A, prod_type=prod_type,M = (New_M_Matrix(64,8),New_M_Matrix(8,2),New_M_Matrix(16,3)))\n",
    "        return tp.ten_prod(U, training_coeff, prod_type=prod_type, M = (New_M_Matrix(64,8),New_M_Matrix(8,2),New_M_Matrix(16,3)))\n",
    "    if M == 'haar':\n",
    "        # Haar Matrix\n",
    "        training_coeff = tp.ten_prod(tp.ten_tran(U, prod_type=prod_type), A, prod_type=prod_type, M = (haar_normalized(64),haar_normalized(8),haar_normalized(16)))\n",
    "        return tp.ten_prod(U, training_coeff, prod_type=prod_type, M = (haar_normalized(64),haar_normalized(8),haar_normalized(16)))\n",
    "    if M == 'data dependent':\n",
    "        # Data Dependent Matrix\n",
    "        u1, _,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],2), n_components=64, n_iter=5, random_state=20)\n",
    "        u2,_,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],3), n_components=8, n_iter=5, random_state=20)\n",
    "        u3,_,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],4), n_components=16, n_iter=5, random_state=20)\n",
    "        training_coeff = tp.ten_prod(tp.ten_tran(U, prod_type=prod_type), A, prod_type=prod_type, M = (u1,u2,u3))\n",
    "        return tp.ten_prod(U, training_coeff, prod_type=prod_type, M = (u1,u2,u3))\n",
    "    if M == 'random orthogonal':\n",
    "        # Random Orthogonal Matrix\n",
    "        training_coeff = tp.ten_prod(tp.ten_tran(U, prod_type=prod_type), A, prod_type=prod_type,M = (ortho_group.rvs(64),ortho_group.rvs(8),ortho_group.rvs(16)))\n",
    "        return tp.ten_prod(U, training_coeff, prod_type=prod_type, M = (ortho_group.rvs(64),ortho_group.rvs(8),ortho_group.rvs(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# for reproducibility\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# we need the variables\n",
    "#   training_data, training_labels, test_data, test_labels, num_classes\n",
    "num_classes = 2\n",
    "star_plus_data = scipy.io.loadmat('data-starplus-04847-v7.mat')\n",
    "tensor_PS, labels = starp.get_labels(star_plus_data)\n",
    "tensor_PS  = tensor_PS / norm(tensor_PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 1)\n",
      "(80, 64, 64, 8, 16)\n"
     ]
    }
   ],
   "source": [
    "print(np.transpose(labels).shape)\n",
    "print(np.moveaxis(tensor_PS, -1, 0).shape)\n",
    "training_data, test_data, training_labels, test_labels = train_test_split(np.moveaxis(tensor_PS, -1, 0), np.transpose(labels), test_size=0.33, random_state=42)\n",
    "(unique, counts) = np.unique(test_labels, return_counts=True)\n",
    "(unique, counts) = np.unique(training_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 53, 64, 8, 16)\n",
      "(64, 27, 64, 8, 16)\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# move the label number to second axis\n",
    "training_data = np.moveaxis(training_data, 0, 1)\n",
    "test_data = np.moveaxis(test_data, 0, 1)\n",
    "print(training_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "# create the boolean array for training and testing\n",
    "boolean_list = []\n",
    "for i in (training_labels):\n",
    "    boolean_list.append(i[0])\n",
    "boolean_array_training = np.asarray(boolean_list)\n",
    "print(boolean_array_training)\n",
    "\n",
    "boolean_list = []\n",
    "for i in (test_labels):\n",
    "    boolean_list.append(i[0])\n",
    "boolean_array_testing = np.asarray(boolean_list)\n",
    "print(boolean_array_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HaarMatrix utilized for m-product\n",
    "def haarMatrix(n):\n",
    "    # n is the power of 2\n",
    "    if n > 2:\n",
    "        M = haarMatrix(n / 2)\n",
    "    else:\n",
    "        return np.array([[1, 1], [1, -1]])\n",
    "    M_n = np.kron(M, [1, 1])\n",
    "    M_i = np.sqrt(n/2)*np.kron(np.eye(len(M)), [1, -1])\n",
    "    M = np.vstack((M_n, M_i))\n",
    "    return M\n",
    "def haar_normalized(n):\n",
    "    M = haarMatrix(n)\n",
    "    M = M/np.sqrt(np.sum(M[0]))\n",
    "    return M\n",
    "\n",
    "def New_M_Matrix(dimension,bandwidth):\n",
    "    A = np.eye(dimension)\n",
    "    for i in range(0, -bandwidth, -1):\n",
    "        A += np.eye(dimension, k = i -1)\n",
    "    for i in range(dimension):\n",
    "        temp = np.sum(A[i])\n",
    "        for k in range(dimension):\n",
    "            if A[i][k] == 1:\n",
    "                A[i][k] = 1/temp\n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# form local t-svd\n",
    "# num_class should be 2\n",
    "#num_classes = len(np.unique(training_labels))\n",
    "#k = 5\n",
    "\n",
    "#U = []\n",
    "def create_basis(M_choice,num_classes,k,training_data,prod_type):\n",
    "    U = []\n",
    "    #print(num_classes)\n",
    "    for i in range(0,num_classes):\n",
    "        if M_choice == 'band':\n",
    "            # Bandwidth Matrix\n",
    "            u, _, _, _ = tp.ten_svd(training_data[:, boolean_array_training == i, :], k, prod_type=prod_type, M = (New_M_Matrix(64,8),New_M_Matrix(8,2),New_M_Matrix(16,3)))\n",
    "            U.append(u)\n",
    "        elif M_choice == 'haar':\n",
    "            # Haar Matrix\n",
    "            u, _, _, _ = tp.ten_svd(training_data[:, boolean_array_training == i, :], k, prod_type=prod_type, M = (haar_normalized(64),haar_normalized(8),haar_normalized(16)))\n",
    "            U.append(u)\n",
    "        elif M_choice == 'data dependent':\n",
    "            # Data Dependent Matrix\n",
    "            u1, _,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],2), n_components=64, n_iter=5, random_state=20)\n",
    "            u2,_,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],3), n_components=8, n_iter=5, random_state=20)\n",
    "            u3,_,_ = randomized_svd(modek_unfold(training_data[:, :, :, :, :],4), n_components=16, n_iter=5, random_state=20)\n",
    "            u, _, _, _ = tp.ten_svd(training_data[:, boolean_array_training == i, :], k, prod_type=prod_type, M = (u1,u2,u3))\n",
    "            U.append(u)\n",
    "        elif M_choice == 'random orthogonal':\n",
    "            # Random Orthogonal Matrix\n",
    "            u, _, _, _ = tp.ten_svd(training_data[:, boolean_array_training == i, :], k, prod_type=prod_type, M = (ortho_group.rvs(64),ortho_group.rvs(8),ortho_group.rvs(16)))\n",
    "            U.append(u)\n",
    "    \n",
    "    return U\n",
    "    \n",
    "def create_test_error(M_choice,U,k,num_classes,boolean_array_testing,test_data,prod_type='m'):\n",
    "    #initialize test_error\n",
    "    test_error = np.zeros([num_classes, test_data.shape[1]])\n",
    "    \n",
    "    #find error\n",
    "    for i in range(num_classes):\n",
    "        test_projection = projection_m_prod_type(test_data, U[i], M_choice)\n",
    "        test_error[i, :] = sm.frobenius_metric(test_data, test_projection, axis=1)\n",
    "        \n",
    "    #classification\n",
    "    test_predicted_classes = np.argmin(test_error, axis=0).reshape(-1)\n",
    "    \n",
    "    test_num_correct = np.sum(test_predicted_classes == boolean_array_testing)\n",
    "    test_error = test_num_correct / test_data.shape[1]\n",
    "    print('M = {}, k = {}'.format(M_choice, k))\n",
    "    print('test accuracy = %0.2f' % (100 * test_error))\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_accuracy_for_given_M(M_choice,num_classes,training_data,test_data,k_list):\n",
    "    prod_type = 'm'\n",
    "    errors_for_given_M_list = []\n",
    "    for i in range(0,len(k_list)):\n",
    "        k = k_list[i]\n",
    "        U = create_basis(M_choice,num_classes,k,training_data,prod_type)\n",
    "        test_error = create_test_error(M_choice,U,k,num_classes,boolean_array_testing,test_data,prod_type)\n",
    "        errors_for_given_M_list.append(test_error)\n",
    "    return errors_for_given_M_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "M_choices = ['haar','band','data dependent','random orthogonal']\n",
    "k_list = np.arange(1,11,1)\n",
    "\n",
    "column_names = ['M','k','error']\n",
    "test_error_df = pd.DataFrame(columns=column_names)\n",
    "#print(test_error_df)\n",
    "for M_choice in M_choices:\n",
    "    print(M)\n",
    "    num_classes = len(np.unique(training_labels))\n",
    "    M_list = [M_choice] * k_list.shape[0]\n",
    "    #print(M_list)\n",
    "    error_for_given_M_list = find_best_accuracy_for_given_M(M_choice,num_classes,training_data,test_data,k_list)\n",
    "    print(error_for_given_M_list)\n",
    "    #creating dataframe rows\n",
    "    M_errors = pd.DataFrame(\n",
    "    {'M' : M_list,\n",
    "    'k' : k_list,\n",
    "    'error': error_for_given_M_list}\n",
    "    )\n",
    "    test_error_df = test_error_df.append(M_errors)\n",
    "    \n",
    "print(test_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = test_error_df.groupby('M')\n",
    "maximums = grouped_df['error'].max()\n",
    "maximums = maximums.reset_index()\n",
    "print(maximums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   M   k     error\n",
      "0               haar   1  0.851852\n",
      "1               haar   2  0.888889\n",
      "2               haar   3  0.888889\n",
      "3               haar   4  0.925926\n",
      "4               haar   5  0.888889\n",
      "5               haar   6  0.888889\n",
      "6               haar   7  0.888889\n",
      "7               haar   8  0.851852\n",
      "8               haar   9  0.814815\n",
      "9               haar  10  0.851852\n",
      "0               band   1  0.592593\n",
      "1               band   2  0.518519\n",
      "2               band   3  0.407407\n",
      "3               band   4  0.555556\n",
      "4               band   5  0.555556\n",
      "5               band   6  0.555556\n",
      "6               band   7  0.555556\n",
      "7               band   8  0.407407\n",
      "8               band   9  0.518519\n",
      "9               band  10  0.555556\n",
      "0     data dependent   1  0.814815\n",
      "1     data dependent   2  0.666667\n",
      "2     data dependent   3  0.666667\n",
      "3     data dependent   4  0.703704\n",
      "4     data dependent   5  0.703704\n",
      "5     data dependent   6  0.740741\n",
      "6     data dependent   7  0.666667\n",
      "7     data dependent   8  0.703704\n",
      "8     data dependent   9  0.629630\n",
      "9     data dependent  10  0.555556\n",
      "0  random orthogonal   1  0.555556\n",
      "1  random orthogonal   2  0.407407\n",
      "2  random orthogonal   3  0.592593\n",
      "3  random orthogonal   4  0.333333\n",
      "4  random orthogonal   5  0.333333\n",
      "5  random orthogonal   6  0.518519\n",
      "6  random orthogonal   7  0.592593\n",
      "7  random orthogonal   8  0.481481\n",
      "8  random orthogonal   9  0.629630\n",
      "9  random orthogonal  10  0.592593\n"
     ]
    }
   ],
   "source": [
    "print(test_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
